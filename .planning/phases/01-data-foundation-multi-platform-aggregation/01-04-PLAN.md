---
phase: 01-data-foundation-multi-platform-aggregation
plan: 04
type: execute
wave: 2
depends_on:
  - 01-01
  - 01-02
files_modified:
  - src/crawlers/axs.ts
autonomous: true
requirements:
  - DATA-02

must_haves:
  truths:
    - System scrapes AXS/Live Nation website for Stockholm music events
    - JavaScript-rendered content is properly loaded before extraction
    - Events are normalized and stored in database
  artifacts:
    - path: "src/crawlers/axs.ts"
      provides: "Playwright-based crawler for AXS/Live Nation"
      exports: ["crawlAXS"]
      min_lines: 100
  key_links:
    - from: "src/crawlers/axs.ts"
      to: "crawlee"
      via: "uses PlaywrightCrawler for dynamic content"
      pattern: "new PlaywrightCrawler"
    - from: "src/crawlers/axs.ts"
      to: "src/normalization/transformers.ts"
      via: "transforms scraped data"
      pattern: "transformAXSEvent"
    - from: "src/crawlers/axs.ts"
      to: "src/storage/event-repository.ts"
      via: "saves events to database"
      pattern: "upsertEvent"
---

<objective>
Implement Playwright-based web scraper for AXS/Live Nation to collect Stockholm music events. AXS has JavaScript-heavy pages requiring browser automation rather than simple HTML parsing.

Purpose: AXS/Live Nation covers big venues and major festivals in Stockholm. Their website uses dynamic JavaScript loading, making Playwright necessary to wait for content to render before extraction.

Output: Working PlaywrightCrawler that extracts Stockholm events from AXS, handles pagination, waits for dynamic content loading, and stores normalized events in database.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-data-foundation-multi-platform-aggregation/01-RESEARCH.md
@.planning/phases/01-data-foundation-multi-platform-aggregation/01-01-SUMMARY.md
@.planning/phases/01-data-foundation-multi-platform-aggregation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PlaywrightCrawler for AXS with dynamic content handling</name>
  <files>
    src/crawlers/axs.ts
  </files>
  <action>
Implement AXS crawler following RESEARCH.md Pattern 1 (Crawlee Strategy Pattern) and addressing Pitfall 2 (JavaScript rendering race conditions):

1. Import dependencies:
   ```typescript
   import { PlaywrightCrawler, log } from 'crawlee';
   import { transformAXSEvent } from '../normalization/transformers.js';
   import { upsertEvent } from '../storage/event-repository.js';
   import { config } from '../config/env.js';
   ```

2. Define AXS URL patterns for Stockholm:
   ```typescript
   const AXS_STOCKHOLM_URL = 'https://www.axs.com/se/stockholm/events/music';
   // Note: Verify actual URL structure during implementation - may need adjustment
   ```

3. Create crawlAXS function with PlaywrightCrawler:
   ```typescript
   export async function crawlAXS(): Promise<{ success: number; failed: number }> {
     let success = 0;
     let failed = 0;

     const crawler = new PlaywrightCrawler({
       maxConcurrency: config.CRAWL_CONCURRENCY,
       requestHandlerTimeoutSecs: 60,
       maxRequestRetries: 3,

       requestHandler: async ({ page, request, enqueueLinks }) => {
         log.info(`Processing AXS page: ${request.url}`);

         // CRITICAL: Wait for events to load (prevents Pitfall 2)
         // Try multiple strategies in order of reliability:
         try {
           // Strategy 1: Wait for event cards to appear
           await page.waitForSelector('.event-card, .event-item, [data-testid="event"]', {
             timeout: 15000
           });

           // Strategy 2: Wait for loading spinner to disappear
           await page.waitForSelector('.loading, .spinner', {
             state: 'hidden',
             timeout: 5000
           }).catch(() => {
             // Loading spinner might not exist, that's ok
           });

           // Strategy 3: Wait for network to be idle
           await page.waitForLoadState('networkidle', { timeout: 10000 }).catch(() => {
             log.warning('Network did not become idle, proceeding anyway');
           });

         } catch (error) {
           log.error(`Failed to load events on ${request.url}: ${error}`);
           return;
         }

         // Verify minimum event count loaded (prevents extracting partial results)
         const eventCount = await page.locator('.event-card, .event-item, [data-testid="event"]').count();
         if (eventCount < 3 && !request.url.includes('page=')) {
           log.warning(`Only ${eventCount} events found, may be incomplete load`);
         }

         // Extract events using page.$$eval
         const rawEvents = await page.$$eval(
           '.event-card, .event-item, [data-testid="event"]',
           (elements) => elements.map(el => ({
             name: el.querySelector('.event-name, h3, [data-testid="event-name"]')?.textContent?.trim(),
             artist: el.querySelector('.artist-name, .performer, [data-testid="artist"]')?.textContent?.trim(),
             venue: el.querySelector('.venue-name, .location, [data-testid="venue"]')?.textContent?.trim(),
             date: el.querySelector('time')?.getAttribute('datetime') ||
                   el.querySelector('.event-date, [data-testid="date"]')?.textContent?.trim(),
             genre: el.querySelector('.genre, .category')?.textContent?.trim(),
             url: el.querySelector('a')?.href,
             price: el.querySelector('.price, [data-testid="price"]')?.textContent?.trim(),
             id: el.querySelector('a')?.href?.split('/').pop()
           }))
         );

         log.info(`Extracted ${rawEvents.length} events from ${request.url}`);

         // Filter for Stockholm events only (in case URL returns broader results)
         const stockholmEvents = rawEvents.filter(event =>
           event.venue?.toLowerCase().includes('stockholm') ||
           request.url.includes('stockholm')
         );

         // Transform and save each event
         for (const rawEvent of stockholmEvents) {
           if (!rawEvent.name || !rawEvent.url) {
             log.warning('Skipping incomplete event:', rawEvent);
             failed++;
             continue;
           }

           const normalized = transformAXSEvent({
             ...rawEvent,
             id: rawEvent.id || `axs-${Date.now()}-${Math.random()}`,
             venue: rawEvent.venue || 'Unknown Stockholm Venue'
           });

           if (!normalized.success) {
             log.warning('Failed to normalize AXS event:', normalized.errors);
             failed++;
             continue;
           }

           try {
             await upsertEvent(normalized.data);
             success++;
           } catch (error) {
             log.error('Failed to save event:', error);
             failed++;
           }
         }

         // Handle pagination
         await enqueueLinks({
           selector: 'a.next-page, a[rel="next"], [data-testid="next-page"]',
           label: 'PAGINATION'
         });
       },

       failedRequestHandler: async ({ request, log }) => {
         log.error(`Request failed after retries: ${request.url}`);
         failed++;
       }
     });

     await crawler.run([AXS_STOCKHOLM_URL]);

     log.info(`AXS crawl complete: ${success} success, ${failed} failed`);
     return { success, failed };
   }
   ```

4. Add helper function to extract date from various formats:
   ```typescript
   function parseAXSDate(dateStr: string): Date | null {
     // Handle ISO 8601
     if (dateStr.includes('T')) {
       return new Date(dateStr);
     }

     // Handle "Jun 15, 2026" format
     try {
       return new Date(dateStr);
     } catch {
       return null;
     }
   }
   ```

Note: Selector patterns (.event-card, .event-item, etc.) are educated guesses based on common patterns. During execution, inspect actual AXS page structure and adjust selectors accordingly. Use multiple fallback selectors to handle variations in page structure.

CRITICAL for Pitfall 2: Must wait for events to load completely before extraction. Use waitForSelector with reasonable timeout, check for loading spinners, and verify minimum event count. Do NOT rely solely on page.waitForLoadState('load') as it fires before JavaScript renders events.
  </action>
  <verify>
Test AXS crawler (may need to adjust selectors based on actual page structure):
  cat > test-crawl-axs.ts << 'EOF'
import { crawlAXS } from './src/crawlers/axs.js';
import { db } from './src/db/client.js';
import { events } from './src/db/schema.js';
import { sql } from 'drizzle-orm';

// Run crawler
console.log('Starting AXS crawler...');
const result = await crawlAXS();
console.log('Crawl result:', result);

// Verify events stored
const stored = await db.select().from(events).where(sql`source_platform = 'axs'`);
console.log(`Stored ${stored.length} AXS events`);

// Check data quality
if (stored.length > 0) {
  const sample = stored[0];
  console.log('Sample event:', {
    name: sample.name,
    venue: sample.venue,
    genre: sample.genre,
    date: sample.date
  });
}

console.log('Success rate:', result.success / (result.success + result.failed));
EOF

  tsx test-crawl-axs.ts
  Expected:
  - Crawler completes without crashing
  - Success count > 0
  - Events stored in database

Verify Playwright browser launches:
  npm run dev
  # Watch logs for Playwright initialization

Check for race condition issues:
  # If crawler consistently returns 0 events, selectors need adjustment
  # If crawler returns <5 events but manual browsing shows more, increase wait times
  </verify>
  <done>
- PlaywrightCrawler extracts events from AXS/Live Nation website
- Multiple wait strategies ensure JavaScript content fully loads
- Minimum event count check prevents extracting partial results
- Events are normalized using transformAXSEvent
- Stockholm filtering applied (venue contains "stockholm" or URL indicates Stockholm)
- Pagination handled automatically via enqueueLinks
- Events saved to database with upsert logic
- Failed extractions logged for debugging
  </done>
</task>

<task type="auto">
  <name>Task 2: Add selector refinement and Stockholm filtering</name>
  <files>
    src/crawlers/axs.ts
  </files>
  <action>
After initial implementation, refine the crawler based on actual AXS page structure:

1. **During execution, inspect the actual AXS page:**
   - Open AXS Stockholm events page in browser
   - Use browser DevTools to inspect event card structure
   - Identify correct CSS selectors for: event name, artist, venue, date, price, URL
   - Update selectors in page.$$eval to match actual structure

2. **Add Stockholm-specific filtering:**
   - Parse venue names and check against known Stockholm venues from venue-mappings.ts
   - Check if event date/location metadata includes Stockholm
   - Filter out events from other Swedish cities (Gothenburg, Malm√∂)

3. **Handle edge cases:**
   - Events without artist name: Use event name as artist
   - Events without genre: Default to 'other'
   - Events with "TBA" or "TBD" dates: Skip or mark for manual review
   - Events with relative dates ("Tomorrow", "This Weekend"): Parse to absolute dates

4. **Add robust error handling:**
   ```typescript
   try {
     const rawEvents = await page.$$eval(...);
     // Processing
   } catch (error) {
     // If $$eval fails, page structure likely changed
     log.error('Failed to extract events, page structure may have changed');

     // Take screenshot for debugging
     await page.screenshot({
       path: `./storage/debug-axs-${Date.now()}.png`
     });

     throw error;
   }
   ```

5. **Implement progress tracking:**
   - Log every 10 events processed
   - Log total events extracted per page
   - Track and log cumulative success/failure rates

Note: This task involves refining selectors based on actual page structure. If selectors are incorrect, crawler will extract empty arrays or malformed data. Use browser DevTools extensively during implementation.

If AXS page structure is substantially different from assumptions:
- Document actual structure in comments
- Adjust extraction strategy (may need to extract JSON from script tags instead of DOM parsing)
- Consider using API endpoints if discoverable (check Network tab in DevTools)
  </action>
  <verify>
Verify Stockholm filtering works:
  tsx -e "
    import { crawlAXS } from './src/crawlers/axs.js';
    import { db } from './src/db/client.js';
    import { events } from './src/db/schema.js';
    import { sql } from 'drizzle-orm';

    await crawlAXS();

    // Check all stored events are Stockholm-related
    const nonStockholm = await db.select()
      .from(events)
      .where(sql\`source_platform = 'axs' AND venue NOT ILIKE '%stockholm%'\`);

    console.log('Non-Stockholm events:', nonStockholm.length);
    console.log('Expected: 0 (all events should be Stockholm)');
  "

Check data completeness:
  docker exec -it $(docker-compose ps -q postgres) psql -U dev -d stockholm_events -c "
    SELECT
      COUNT(*) as total,
      COUNT(name) as has_name,
      COUNT(venue) as has_venue,
      COUNT(date) as has_date,
      COUNT(genre) as has_genre
    FROM events
    WHERE source_platform = 'axs';
  "
  Expected: All counts equal (no NULL required fields)

Test error handling:
  # Temporarily break a selector to verify error handling works
  # Should take screenshot and log clear error message
  </verify>
  <done>
- Selectors refined based on actual AXS page structure
- Stockholm filtering removes non-Stockholm events
- Edge cases handled (missing artist, TBA dates, etc.)
- Error handling includes screenshots for debugging
- Progress logging tracks extraction success
- All stored AXS events have complete required fields
- Data quality verified (no NULL required fields)
  </done>
</task>

</tasks>

<verification>
End-to-end AXS crawler verification:

1. Full crawl test:
   ```bash
   tsx -e "import { crawlAXS } from './src/crawlers/axs.js'; await crawlAXS();"
   ```
   Expected: Completes successfully, logs progress

2. Database verification:
   ```sql
   -- Check event count
   SELECT COUNT(*) FROM events WHERE source_platform = 'axs';
   -- Expected: > 20 events (AXS covers major venues)

   -- Verify Stockholm filtering
   SELECT venue, COUNT(*)
   FROM events
   WHERE source_platform = 'axs'
   GROUP BY venue;
   -- Expected: All venues are Stockholm-based

   -- Check data quality
   SELECT name, artist, venue, genre, date
   FROM events
   WHERE source_platform = 'axs'
   LIMIT 5;
   -- Expected: All fields populated, venues normalized, genres canonical
   ```

3. Compare with manual browsing:
   - Open AXS Stockholm page in browser
   - Count events on first page
   - Compare with events extracted by crawler
   - Expected: Crawler extracts >= 90% of visible events
</verification>

<success_criteria>
- PlaywrightCrawler successfully extracts events from AXS website
- JavaScript content fully loads before extraction (no race conditions)
- Events are Stockholm-specific (venue filtering works)
- Events are normalized using transformAXSEvent
- Database contains >20 AXS events after crawl
- All stored events have complete required fields
- Pagination handled (multiple pages crawled if available)
- Error handling includes screenshots for debugging
- Success rate >80% (some events may fail validation, but most succeed)
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-foundation-multi-platform-aggregation/01-04-SUMMARY.md`
</output>
