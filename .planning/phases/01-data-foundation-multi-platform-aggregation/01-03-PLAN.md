---
phase: 01-data-foundation-multi-platform-aggregation
plan: 03
type: execute
wave: 2
depends_on:
  - 01-01
  - 01-02
files_modified:
  - src/crawlers/ticketmaster.ts
  - src/crawlers/ticketmaster-api-client.ts
  - src/storage/event-repository.ts
autonomous: true
requirements:
  - DATA-01

must_haves:
  truths:
    - System fetches Stockholm music events from Ticketmaster Discovery API
    - Only events within next 12 months are fetched
    - API rate limits are respected (5000 calls/day, 5 req/sec)
    - Fetched events are normalized and stored in database
  artifacts:
    - path: "src/crawlers/ticketmaster-api-client.ts"
      provides: "Ticketmaster Discovery API client with rate limiting"
      exports: ["TicketmasterClient"]
      min_lines: 60
    - path: "src/crawlers/ticketmaster.ts"
      provides: "Stockholm event fetcher using Ticketmaster API"
      exports: ["crawlTicketmaster"]
      min_lines: 80
    - path: "src/storage/event-repository.ts"
      provides: "Database operations for event storage"
      exports: ["saveEvent", "upsertEvent"]
      min_lines: 40
  key_links:
    - from: "src/crawlers/ticketmaster.ts"
      to: "src/crawlers/ticketmaster-api-client.ts"
      via: "uses API client for fetching"
      pattern: "new TicketmasterClient"
    - from: "src/crawlers/ticketmaster.ts"
      to: "src/normalization/transformers.ts"
      via: "transforms API responses"
      pattern: "transformTicketmasterEvent"
    - from: "src/crawlers/ticketmaster.ts"
      to: "src/storage/event-repository.ts"
      via: "saves normalized events"
      pattern: "upsertEvent"
---

<objective>
Implement the Ticketmaster Discovery API crawler to fetch Stockholm music events. This crawler uses the official API (avoiding scraping) with proper rate limiting, pagination handling, and 12-month window filtering.

Purpose: Ticketmaster is a major source of Stockholm events covering large venues and international acts. Using their official API provides reliable, structured data with 230K+ events globally and avoids scraping brittleness.

Output: Working Ticketmaster API client with rate limiting, Stockholm event fetcher with 12-month filtering, and database storage integration.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-data-foundation-multi-platform-aggregation/01-RESEARCH.md
@.planning/phases/01-data-foundation-multi-platform-aggregation/01-01-SUMMARY.md
@.planning/phases/01-data-foundation-multi-platform-aggregation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Ticketmaster Discovery API client with rate limiting</name>
  <files>
    src/crawlers/ticketmaster-api-client.ts
  </files>
  <action>
Implement API client following Ticketmaster Discovery API documentation:

1. Create TicketmasterClient class with configuration:
   - apiKey: string (from config.TICKETMASTER_API_KEY)
   - baseURL: 'https://app.ticketmaster.com/discovery/v2'
   - rateLimiter: Track requests per second (max 5 req/sec) and daily (max 5000/day)
   - requestCounter: Count total requests made in current day

2. Implement rate limiting:
   ```typescript
   private async waitForRateLimit(): Promise<void> {
     // Per-second rate limit: max 5 requests per second
     const now = Date.now();
     const elapsed = now - this.lastRequestTime;
     if (elapsed < 200) {  // 200ms = 5 req/sec
       await new Promise(resolve => setTimeout(resolve, 200 - elapsed));
     }
     this.lastRequestTime = Date.now();

     // Daily quota check
     if (this.dailyRequestCount >= 5000) {
       throw new Error('Ticketmaster API daily quota exhausted (5000 requests)');
     }
     this.dailyRequestCount++;
   }
   ```

3. Implement searchEvents method:
   ```typescript
   async searchEvents(params: {
     city?: string;
     stateCode?: string;
     countryCode?: string;
     startDateTime?: string;
     endDateTime?: string;
     classificationName?: string;
     page?: number;
     size?: number;
   }): Promise<TicketmasterResponse> {
     await this.waitForRateLimit();

     const queryParams = new URLSearchParams({
       apikey: this.apiKey,
       ...params
     });

     const response = await fetch(`${this.baseURL}/events.json?${queryParams}`);

     if (!response.ok) {
       if (response.status === 429) {
         throw new Error('Rate limit exceeded');
       }
       throw new Error(`API error: ${response.status} ${response.statusText}`);
     }

     return response.json();
   }
   ```

4. Add getEventDetails method for fetching single event by ID (used for updates):
   ```typescript
   async getEventDetails(eventId: string): Promise<any> {
     await this.waitForRateLimit();
     const response = await fetch(`${this.baseURL}/events/${eventId}.json?apikey=${this.apiKey}`);
     if (!response.ok) throw new Error(`Event not found: ${eventId}`);
     return response.json();
   }
   ```

5. Add daily quota reset logic (reset counter at midnight UTC):
   ```typescript
   private resetDailyQuotaIfNeeded() {
     const now = new Date();
     if (now.getUTCDate() !== this.lastResetDate.getUTCDate()) {
       this.dailyRequestCount = 0;
       this.lastResetDate = now;
     }
   }
   ```

6. Export TypeScript types for API responses:
   ```typescript
   export interface TicketmasterResponse {
     _embedded?: { events: any[] };
     page: { size: number; totalElements: number; totalPages: number; number: number };
   }
   ```

Note: CRITICAL - Rate limiting prevents API quota exhaustion (Pitfall 1 from RESEARCH.md). Must wait 200ms between requests (5 req/sec limit) and track daily quota. Log warning at 4500 requests.
  </action>
  <verify>
Test rate limiting:
  cat > test-tm-client.ts << 'EOF'
import { TicketmasterClient } from './src/crawlers/ticketmaster-api-client.js';
import { config } from './src/config/env.js';

const client = new TicketmasterClient(config.TICKETMASTER_API_KEY);

// Test rate limiting: 10 requests should take at least 2 seconds
const start = Date.now();
for (let i = 0; i < 10; i++) {
  try {
    await client.searchEvents({ city: 'Stockholm', countryCode: 'SE', size: 1 });
  } catch (err) {
    console.log('Request', i, 'failed:', err.message);
  }
}
const elapsed = Date.now() - start;
console.log(`10 requests took ${elapsed}ms (expected >2000ms): ${elapsed > 2000 ? 'PASS' : 'FAIL'}`);
EOF

  tsx test-tm-client.ts
  Expected: Takes at least 2 seconds, prints PASS

Check API response structure:
  cat > test-tm-response.ts << 'EOF'
import { TicketmasterClient } from './src/crawlers/ticketmaster-api-client.js';
import { config } from './src/config/env.js';

const client = new TicketmasterClient(config.TICKETMASTER_API_KEY);
const result = await client.searchEvents({ city: 'Stockholm', countryCode: 'SE', size: 1 });

console.log('Has events:', result._embedded?.events ? 'PASS' : 'FAIL');
console.log('Has pagination:', result.page ? 'PASS' : 'FAIL');
EOF

  tsx test-tm-response.ts
  Expected: Both checks PASS
  </verify>
  <done>
- TicketmasterClient respects 5 req/sec rate limit
- Daily quota tracked and enforced (5000 requests/day)
- searchEvents method supports all required filters
- getEventDetails method fetches single event by ID
- API errors handled gracefully with clear messages
- Rate limiting verified to work (10 requests take 2+ seconds)
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement Stockholm event fetcher with 12-month window and database storage</name>
  <files>
    src/crawlers/ticketmaster.ts
    src/storage/event-repository.ts
  </files>
  <action>
Create the main Ticketmaster crawler and database repository:

**Part A: Event repository (event-repository.ts)**

1. Create database operations using Drizzle ORM:
   ```typescript
   import { db } from '../db/client.js';
   import { events } from '../db/schema.js';
   import { eq, and } from 'drizzle-orm';
   import type { Event } from '../normalization/schemas.js';

   export async function upsertEvent(event: Event): Promise<void> {
     // Use INSERT ... ON CONFLICT to handle duplicates gracefully
     await db.insert(events)
       .values(event)
       .onConflictDoUpdate({
         target: [events.venue, events.date],
         set: {
           name: event.name,
           artist: event.artist,
           genre: event.genre,
           ticketUrl: event.ticketUrl,
           price: event.price,
           updatedAt: new Date()
         }
       });
   }

   export async function saveEvent(event: Event): Promise<boolean> {
     try {
       await upsertEvent(event);
       return true;
     } catch (error) {
       console.error('Failed to save event:', error);
       return false;
     }
   }

   export async function eventExists(sourceId: string, sourcePlatform: string): Promise<boolean> {
     const result = await db.select()
       .from(events)
       .where(and(
         eq(events.sourceId, sourceId),
         eq(events.sourcePlatform, sourcePlatform)
       ))
       .limit(1);
     return result.length > 0;
   }
   ```

**Part B: Ticketmaster crawler (ticketmaster.ts)**

2. Implement crawlTicketmaster function:
   ```typescript
   import { TicketmasterClient } from './ticketmaster-api-client.js';
   import { transformTicketmasterEvent } from '../normalization/transformers.js';
   import { upsertEvent } from '../storage/event-repository.js';
   import { config } from '../config/env.js';

   export async function crawlTicketmaster(): Promise<{ success: number; failed: number }> {
     const client = new TicketmasterClient(config.TICKETMASTER_API_KEY);

     // Calculate 12-month window
     const startDate = new Date();
     const endDate = new Date();
     endDate.setMonth(endDate.getMonth() + 12);

     let success = 0;
     let failed = 0;
     let page = 0;
     const pageSize = 200;  // Max allowed by API

     console.log(`Fetching Ticketmaster events in Stockholm from ${startDate.toISOString()} to ${endDate.toISOString()}`);

     while (true) {
       const response = await client.searchEvents({
         city: 'Stockholm',
         countryCode: 'SE',
         classificationName: 'Music',
         startDateTime: startDate.toISOString(),
         endDateTime: endDate.toISOString(),
         page,
         size: pageSize
       });

       const rawEvents = response._embedded?.events || [];
       if (rawEvents.length === 0) break;

       console.log(`Processing page ${page}, ${rawEvents.length} events`);

       for (const rawEvent of rawEvents) {
         const normalized = transformTicketmasterEvent(rawEvent);

         if (!normalized.success) {
           console.warn('Failed to normalize event:', normalized.errors);
           failed++;
           continue;
         }

         const saved = await upsertEvent(normalized.data);
         if (saved) success++;
         else failed++;
       }

       // Check if more pages exist
       if (page >= response.page.totalPages - 1) break;
       page++;
     }

     console.log(`Ticketmaster crawl complete: ${success} success, ${failed} failed`);
     return { success, failed };
   }
   ```

3. Add progress logging every 10 pages to track long-running crawls

4. Handle API errors gracefully:
   - 429 (rate limit): Log warning and continue (already handled by client)
   - 500 (server error): Retry up to 3 times with exponential backoff
   - Other errors: Log and continue to next event

Note: Use INSERT ... ON CONFLICT (upsert) to handle duplicate events without crashing (prevents Pitfall 6 from RESEARCH.md). This handles race conditions when same event appears on multiple pages.
  </action>
  <verify>
Run Ticketmaster crawler and verify results:
  cat > test-crawl-tm.ts << 'EOF'
import { crawlTicketmaster } from './src/crawlers/ticketmaster.js';
import { db } from './src/db/client.js';
import { events } from './src/db/schema.js';
import { sql } from 'drizzle-orm';

// Clear test data
await db.delete(events).where(sql`source_platform = 'ticketmaster'`);

// Run crawler
const result = await crawlTicketmaster();
console.log('Crawl result:', result);

// Verify events stored
const stored = await db.select().from(events).where(sql`source_platform = 'ticketmaster'`);
console.log(`Stored ${stored.length} events`);

// Check data quality
const sample = stored[0];
if (sample) {
  console.log('Sample event:', {
    name: sample.name,
    venue: sample.venue,
    genre: sample.genre,
    date: sample.date
  });
  console.log('Has required fields:', sample.name && sample.venue && sample.genre ? 'PASS' : 'FAIL');
}
EOF

  tsx test-crawl-tm.ts
  Expected:
  - Crawl completes without errors
  - Success count > 0
  - Events stored in database with normalized data

Verify 12-month window:
  docker exec -it $(docker-compose ps -q postgres) psql -U dev -d stockholm_events -c "SELECT MIN(date), MAX(date) FROM events WHERE source_platform = 'ticketmaster';"
  Expected: Date range within next 12 months

Check deduplication:
  docker exec -it $(docker-compose ps -q postgres) psql -U dev -d stockholm_events -c "SELECT COUNT(*), COUNT(DISTINCT (venue, date)) FROM events WHERE source_platform = 'ticketmaster';"
  Expected: Both counts equal (no duplicates by venue+date)
  </verify>
  <done>
- upsertEvent handles duplicates gracefully with ON CONFLICT
- crawlTicketmaster fetches all Stockholm music events within 12-month window
- Pagination handled correctly (continues until all pages fetched)
- Events are normalized and stored in database
- Rate limiting prevents API quota exhaustion
- Progress logged during crawl for monitoring
- Duplicate events are updated, not rejected
  </done>
</task>

</tasks>

<verification>
End-to-end Ticketmaster crawler verification:

1. Full crawl test:
   ```bash
   npm run db:push  # Ensure schema is up to date
   tsx -e "import { crawlTicketmaster } from './src/crawlers/ticketmaster.js'; await crawlTicketmaster();"
   ```
   Expected: Completes successfully, logs progress, stores events

2. Database verification:
   ```sql
   -- Check event count
   SELECT COUNT(*) FROM events WHERE source_platform = 'ticketmaster';
   -- Expected: > 100 events (Stockholm has active music scene)

   -- Check data quality
   SELECT name, artist, venue, genre, date
   FROM events
   WHERE source_platform = 'ticketmaster'
   LIMIT 5;
   -- Expected: All fields populated, venues normalized, genres canonical

   -- Check date range
   SELECT
     MIN(date) as earliest,
     MAX(date) as latest,
     MAX(date) - MIN(date) as range_days
   FROM events
   WHERE source_platform = 'ticketmaster';
   -- Expected: range_days <= 365 (12-month window)

   -- Check for duplicates
   SELECT venue, date, COUNT(*)
   FROM events
   WHERE source_platform = 'ticketmaster'
   GROUP BY venue, date
   HAVING COUNT(*) > 1;
   -- Expected: 0 rows (unique constraint enforced)
   ```

3. Rate limiting verification:
   Check logs for rate limit warnings - should not see "daily quota exhausted" message unless running multiple times in same day.
</verification>

<success_criteria>
- TicketmasterClient respects 5 req/sec and 5000/day rate limits
- crawlTicketmaster fetches all Stockholm music events within 12-month window
- Events are normalized using transformTicketmasterEvent
- Events are stored in database with upsert logic (no duplicate errors)
- Pagination handled correctly (all pages fetched)
- Database contains >100 Stockholm events after first crawl
- All stored events have date within next 12 months
- No duplicate venue+date combinations in database
- Rate limiting verified (10 sequential requests take 2+ seconds)
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-foundation-multi-platform-aggregation/01-03-SUMMARY.md`
</output>
