---
phase: 01-data-foundation-multi-platform-aggregation
plan: 05
type: execute
wave: 2
depends_on:
  - 01-01
  - 01-02
files_modified:
  - src/crawlers/dice.ts
autonomous: true
requirements:
  - DATA-03

must_haves:
  truths:
    - System scrapes DICE website for Stockholm music events
    - Dynamic event loading via JavaScript is properly handled
    - Events are normalized and stored in database
  artifacts:
    - path: "src/crawlers/dice.ts"
      provides: "Playwright-based crawler for DICE"
      exports: ["crawlDICE"]
      min_lines: 100
  key_links:
    - from: "src/crawlers/dice.ts"
      to: "crawlee"
      via: "uses PlaywrightCrawler for dynamic content"
      pattern: "new PlaywrightCrawler"
    - from: "src/crawlers/dice.ts"
      to: "src/normalization/transformers.ts"
      via: "transforms scraped data"
      pattern: "transformDICEEvent"
    - from: "src/crawlers/dice.ts"
      to: "src/storage/event-repository.ts"
      via: "saves events to database"
      pattern: "upsertEvent"
---

<objective>
Implement Playwright-based web scraper for DICE to collect Stockholm music events. DICE focuses on clubs and smaller venues with dynamic JavaScript-based event loading.

Purpose: DICE covers the independent venue scene and club events in Stockholm, complementing the larger venues covered by Ticketmaster and AXS. Their site loads events dynamically via infinite scroll or pagination.

Output: Working PlaywrightCrawler that extracts Stockholm events from DICE, handles dynamic content loading and infinite scroll, and stores normalized events in database.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-data-foundation-multi-platform-aggregation/01-RESEARCH.md
@.planning/phases/01-data-foundation-multi-platform-aggregation/01-01-SUMMARY.md
@.planning/phases/01-data-foundation-multi-platform-aggregation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PlaywrightCrawler for DICE with infinite scroll handling</name>
  <files>
    src/crawlers/dice.ts
  </files>
  <action>
Implement DICE crawler following RESEARCH.md patterns and addressing dynamic content loading:

1. Import dependencies:
   ```typescript
   import { PlaywrightCrawler, log } from 'crawlee';
   import { transformDICEEvent } from '../normalization/transformers.js';
   import { upsertEvent } from '../storage/event-repository.js';
   import { config } from '../config/env.js';
   ```

2. Define DICE URL for Stockholm:
   ```typescript
   const DICE_STOCKHOLM_URL = 'https://dice.fm/city/stockholm/events';
   // Note: Verify actual URL during implementation
   ```

3. Create crawlDICE function with infinite scroll handling:
   ```typescript
   export async function crawlDICE(): Promise<{ success: number; failed: number }> {
     let success = 0;
     let failed = 0;

     const crawler = new PlaywrightCrawler({
       maxConcurrency: config.CRAWL_CONCURRENCY,
       requestHandlerTimeoutSecs: 90,  // Longer timeout for infinite scroll
       maxRequestRetries: 3,

       requestHandler: async ({ page, request }) => {
         log.info(`Processing DICE page: ${request.url}`);

         // Wait for initial events to load
         try {
           await page.waitForSelector('[data-testid="event-card"], .event-card, .event-item', {
             timeout: 15000
           });
         } catch (error) {
           log.error(`Failed to load DICE events: ${error}`);
           return;
         }

         // Handle infinite scroll if present
         let previousEventCount = 0;
         let currentEventCount = 0;
         let scrollAttempts = 0;
         const maxScrollAttempts = 20;  // Limit to prevent infinite loops

         while (scrollAttempts < maxScrollAttempts) {
           currentEventCount = await page.locator('[data-testid="event-card"], .event-card, .event-item').count();

           log.info(`Scroll attempt ${scrollAttempts}: ${currentEventCount} events loaded`);

           // If count hasn't changed, we've reached the end
           if (currentEventCount === previousEventCount) {
             break;
           }

           previousEventCount = currentEventCount;

           // Scroll to bottom
           await page.evaluate(() => window.scrollTo(0, document.body.scrollHeight));

           // Wait for new events to load
           await page.waitForTimeout(2000);  // Give time for AJAX requests

           // Check for "loading" indicator
           const isLoading = await page.locator('.loading, .spinner, [data-testid="loading"]').count();
           if (isLoading > 0) {
             await page.waitForSelector('.loading, .spinner, [data-testid="loading"]', {
               state: 'hidden',
               timeout: 10000
             }).catch(() => {
               log.warning('Loading indicator did not disappear');
             });
           }

           scrollAttempts++;
         }

         log.info(`Finished scrolling. Total events loaded: ${currentEventCount}`);

         // Extract all events
         const rawEvents = await page.$$eval(
           '[data-testid="event-card"], .event-card, .event-item',
           (elements) => elements.map(el => {
             // Extract event data
             const nameEl = el.querySelector('[data-testid="event-name"], .event-name, h2, h3');
             const artistEl = el.querySelector('[data-testid="artist-name"], .artist-name, .performer');
             const venueEl = el.querySelector('[data-testid="venue"], .venue-name, .location');
             const dateEl = el.querySelector('time, [data-testid="event-date"], .event-date');
             const genreEl = el.querySelector('[data-testid="genre"], .genre, .category');
             const linkEl = el.querySelector('a[href*="/event/"], a[href*="/events/"]');
             const priceEl = el.querySelector('[data-testid="price"], .price');

             return {
               name: nameEl?.textContent?.trim(),
               artist: artistEl?.textContent?.trim(),
               venue: venueEl?.textContent?.trim(),
               date: dateEl?.getAttribute('datetime') || dateEl?.textContent?.trim(),
               genre: genreEl?.textContent?.trim(),
               url: linkEl?.href,
               price: priceEl?.textContent?.trim(),
               id: linkEl?.href?.split('/').pop()
             };
           })
         );

         log.info(`Extracted ${rawEvents.length} raw events from DICE`);

         // Filter and normalize events
         for (const rawEvent of rawEvents) {
           if (!rawEvent.name || !rawEvent.url) {
             log.warning('Skipping incomplete DICE event:', rawEvent);
             failed++;
             continue;
           }

           // Ensure we have Stockholm events
           const isStockholm =
             rawEvent.venue?.toLowerCase().includes('stockholm') ||
             request.url.includes('stockholm');

           if (!isStockholm && rawEvent.venue) {
             log.debug(`Skipping non-Stockholm event: ${rawEvent.venue}`);
             continue;
           }

           const normalized = transformDICEEvent({
             ...rawEvent,
             id: rawEvent.id || `dice-${Date.now()}-${Math.random()}`,
             venue: rawEvent.venue || 'Stockholm Venue',
             artist: rawEvent.artist || rawEvent.name
           });

           if (!normalized.success) {
             log.warning('Failed to normalize DICE event:', normalized.errors);
             failed++;
             continue;
           }

           try {
             await upsertEvent(normalized.data);
             success++;
           } catch (error) {
             log.error('Failed to save DICE event:', error);
             failed++;
           }
         }
       },

       failedRequestHandler: async ({ request, log }) => {
         log.error(`DICE request failed after retries: ${request.url}`);
         failed++;
       }
     });

     await crawler.run([DICE_STOCKHOLM_URL]);

     log.info(`DICE crawl complete: ${success} success, ${failed} failed`);
     return { success, failed };
   }
   ```

4. Add helper for date parsing from various formats:
   ```typescript
   function parseDICEDate(dateStr: string): Date | null {
     // ISO 8601
     if (dateStr.includes('T')) {
       return new Date(dateStr);
     }

     // Relative dates
     if (dateStr.toLowerCase().includes('tonight')) {
       const tonight = new Date();
       tonight.setHours(20, 0, 0, 0);
       return tonight;
     }

     if (dateStr.toLowerCase().includes('tomorrow')) {
       const tomorrow = new Date();
       tomorrow.setDate(tomorrow.getDate() + 1);
       tomorrow.setHours(20, 0, 0, 0);
       return tomorrow;
     }

     // Standard date parsing
     try {
       return new Date(dateStr);
     } catch {
       return null;
     }
   }
   ```

Note: DICE likely uses infinite scroll for event loading. Must scroll to bottom multiple times until no new events appear. Use waitForTimeout between scrolls to allow AJAX requests to complete. Limit scroll attempts to prevent infinite loops if page structure changes.
  </action>
  <verify>
Test DICE crawler:
  cat > test-crawl-dice.ts << 'EOF'
import { crawlDICE } from './src/crawlers/dice.js';
import { db } from './src/db/client.js';
import { events } from './src/db/schema.js';
import { sql } from 'drizzle-orm';

console.log('Starting DICE crawler...');
const result = await crawlDICE();
console.log('Crawl result:', result);

// Verify events stored
const stored = await db.select().from(events).where(sql`source_platform = 'dice'`);
console.log(`Stored ${stored.length} DICE events`);

// Sample event
if (stored.length > 0) {
  console.log('Sample:', {
    name: stored[0].name,
    venue: stored[0].venue,
    genre: stored[0].genre
  });
}

console.log('Success rate:', (result.success / (result.success + result.failed) * 100).toFixed(1) + '%');
EOF

  tsx test-crawl-dice.ts
  Expected:
  - Crawler completes successfully
  - Success count > 0
  - Events stored in database
  - Success rate > 70%

Check infinite scroll worked:
  # Should see log messages like "Scroll attempt 1: 20 events", "Scroll attempt 2: 40 events", etc.
  # Final count should be > 50 events (DICE usually has many club events)
  </verify>
  <done>
- PlaywrightCrawler extracts events from DICE website
- Infinite scroll handled (scrolls until no new events load)
- Scroll attempts limited to prevent infinite loops
- Events are normalized using transformDICEEvent
- Stockholm filtering applied
- Events saved to database with upsert logic
- Success/failure rates tracked and logged
  </done>
</task>

<task type="auto">
  <name>Task 2: Refine selectors and add DICE-specific event parsing</name>
  <files>
    src/crawlers/dice.ts
  </files>
  <action>
Refine DICE crawler based on actual page structure:

1. **Inspect actual DICE page during execution:**
   - Open https://dice.fm/city/stockholm/events in browser
   - Check DevTools for event card structure
   - Identify selectors for all event fields
   - Note if infinite scroll or pagination is used
   - Check if events load via API (Network tab) - if yes, consider using API directly

2. **Handle DICE-specific date formats:**
   ```typescript
   function parseDICEDateTime(dateStr: string, timeStr?: string): Date {
     // DICE may show dates like "FRI 15 JUN" with separate time "20:00"
     // Combine and parse to full datetime

     if (dateStr.includes('T')) {
       // Already ISO format
       return new Date(dateStr);
     }

     // Parse "FRI 15 JUN" format
     const months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'];
     const parts = dateStr.toLowerCase().match(/(\d+)\s+(\w+)/);

     if (parts) {
       const day = parseInt(parts[1]);
       const monthIndex = months.findIndex(m => parts[2].startsWith(m));
       const year = new Date().getFullYear();

       const date = new Date(year, monthIndex, day);

       // Add time if provided
       if (timeStr) {
         const [hours, minutes] = timeStr.split(':').map(Number);
         date.setHours(hours, minutes);
       }

       return date;
     }

     return new Date(dateStr);
   }
   ```

3. **Add genre detection from DICE categories:**
   - DICE may use tags like "Electronic", "Techno", "House", "Live Music"
   - Extract all genre/tag elements and map to canonical genres
   - Prefer specific genre over broad category

4. **Handle club event specifics:**
   - Club events may have multiple artists/DJs
   - Extract first artist as primary, or join with " / "
   - Handle "Doors: 22:00" format for event start time
   - Price may be shown as "Free", "£10", or "From £5"

5. **Add debug mode for development:**
   ```typescript
   const DEBUG = process.env.DEBUG === 'true';

   if (DEBUG) {
     // Take screenshots during scroll
     await page.screenshot({ path: `./storage/dice-scroll-${scrollAttempts}.png` });

     // Log extracted HTML for first event
     const firstEventHTML = await page.$eval('[data-testid="event-card"]', el => el.outerHTML);
     log.debug('First event HTML:', firstEventHTML);
   }
   ```

6. **Optimize scroll strategy:**
   ```typescript
   // Instead of fixed 2-second waits, use network idle:
   await Promise.race([
     page.waitForLoadState('networkidle', { timeout: 5000 }),
     page.waitForTimeout(2000)  // Fallback
   ]);
   ```

Note: If DICE loads events via API endpoint (discoverable in Network tab), consider using that API directly instead of scraping DOM. This would be faster and more reliable. Check for XHR/Fetch requests to endpoints like `/api/events`.
  </action>
  <verify>
Verify DICE data quality:
  docker exec -it $(docker-compose ps -q postgres) psql -U dev -d stockholm_events -c "
    SELECT
      COUNT(*) as total,
      COUNT(DISTINCT name) as unique_events,
      COUNT(DISTINCT venue) as unique_venues,
      MIN(date) as earliest_event,
      MAX(date) as latest_event
    FROM events
    WHERE source_platform = 'dice';
  "
  Expected:
  - total > 30 (DICE has many club events)
  - unique_venues > 5 (various clubs)
  - Date range within next 12 months

Check for duplicates:
  docker exec -it $(docker-compose ps -q postgres) psql -U dev -d stockholm_events -c "
    SELECT name, venue, date, COUNT(*)
    FROM events
    WHERE source_platform = 'dice'
    GROUP BY name, venue, date
    HAVING COUNT(*) > 1;
  "
  Expected: 0 rows (no duplicates)

Test with DEBUG mode:
  DEBUG=true tsx -e "import { crawlDICE } from './src/crawlers/dice.js'; await crawlDICE();"
  Expected: Screenshots saved to storage/, debug logs visible
  </verify>
  <done>
- Selectors refined based on actual DICE page structure
- DICE-specific date parsing handles various formats
- Multiple artists/DJs handled appropriately
- Club event specifics (doors time, free entry) parsed correctly
- Debug mode available for troubleshooting
- Scroll strategy optimized (network idle vs fixed timeout)
- All stored DICE events have valid dates and complete fields
  </done>
</task>

</tasks>

<verification>
End-to-end DICE crawler verification:

1. Full crawl test:
   ```bash
   tsx -e "import { crawlDICE } from './src/crawlers/dice.js'; await crawlDICE();"
   ```
   Expected: Completes successfully, logs scroll progress

2. Database verification:
   ```sql
   -- Check event count
   SELECT COUNT(*) FROM events WHERE source_platform = 'dice';
   -- Expected: > 30 events (DICE covers club scene extensively)

   -- Verify venue diversity
   SELECT venue, COUNT(*) as event_count
   FROM events
   WHERE source_platform = 'dice'
   GROUP BY venue
   ORDER BY event_count DESC
   LIMIT 10;
   -- Expected: Mix of club venues

   -- Check date distribution
   SELECT DATE_TRUNC('month', date) as month, COUNT(*)
   FROM events
   WHERE source_platform = 'dice'
   GROUP BY month
   ORDER BY month;
   -- Expected: Events distributed across future months
   ```

3. Cross-platform comparison:
   ```sql
   -- Compare coverage across platforms
   SELECT source_platform, COUNT(*) as events
   FROM events
   GROUP BY source_platform;
   -- Expected: Reasonable distribution (Ticketmaster likely highest, DICE second, AXS third)
   ```
</verification>

<success_criteria>
- PlaywrightCrawler successfully extracts events from DICE website
- Infinite scroll handled correctly (all events loaded)
- Events are Stockholm-specific
- Events are normalized using transformDICEEvent
- Database contains >30 DICE events after crawl
- All stored events have complete required fields
- Date parsing handles DICE-specific formats
- Club event specifics (multiple artists, doors time) handled
- No duplicate events in database (venue+date unique constraint enforced)
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-foundation-multi-platform-aggregation/01-05-SUMMARY.md`
</output>
