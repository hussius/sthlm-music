---
phase: 05-wire-scheduling-deduplication-pipeline
plan: 02
type: execute
wave: 2
depends_on:
  - "05-01"
files_modified:
  - src/crawlers/ticketmaster.ts
  - src/crawlers/axs.ts
  - src/crawlers/dice.ts
  - src/crawlers/venues/base-venue-crawler.ts
autonomous: true
requirements:
  - DATA-05
  - QUAL-01

must_haves:
  truths:
    - "All four TypeScript crawlers call deduplicateAndSave() instead of upsertEvent() directly"
    - "Cross-platform duplicate events are merged (same event on Ticketmaster + DICE becomes one DB row with two ticket sources)"
    - "Fuzzy deduplication pipeline (3-stage: exact match → token_set_ratio → manual review queue) is active for every saved event"
    - "The review_queue table exists in the database before deduplicateAndSave() is called"
    - "upsertEvent() is NOT removed from event-repository.ts (deduplicator.ts uses it internally)"
  artifacts:
    - path: "src/crawlers/ticketmaster.ts"
      provides: "Ticketmaster crawler using deduplication pipeline"
      contains: "deduplicateAndSave"
    - path: "src/crawlers/axs.ts"
      provides: "AXS crawler using deduplication pipeline"
      contains: "deduplicateAndSave"
    - path: "src/crawlers/dice.ts"
      provides: "DICE crawler using deduplication pipeline"
      contains: "deduplicateAndSave"
    - path: "src/crawlers/venues/base-venue-crawler.ts"
      provides: "Venue base crawler using deduplication pipeline"
      contains: "deduplicateAndSave"
  key_links:
    - from: "src/crawlers/ticketmaster.ts"
      to: "src/deduplication/deduplicator.ts"
      via: "import deduplicateAndSave + call at line ~110"
      pattern: "deduplicateAndSave"
    - from: "src/crawlers/axs.ts"
      to: "src/deduplication/deduplicator.ts"
      via: "import deduplicateAndSave + call at line ~334"
      pattern: "deduplicateAndSave"
    - from: "src/crawlers/dice.ts"
      to: "src/deduplication/deduplicator.ts"
      via: "import deduplicateAndSave + call at line ~202"
      pattern: "deduplicateAndSave"
    - from: "src/crawlers/venues/base-venue-crawler.ts"
      to: "src/deduplication/deduplicator.ts"
      via: "import deduplicateAndSave + call at line ~186"
      pattern: "deduplicateAndSave"
---

<objective>
Replace direct `upsertEvent()` calls in all four TypeScript crawlers with `deduplicateAndSave()`, and ensure the `review_queue` table exists in the database before wiring takes effect.

Purpose: Currently every crawler bypasses the 3-stage deduplication pipeline (exact match + fuzzy token_set_ratio + manual review queue) and calls `upsertEvent()` directly. Only the database-level `(venue, date)` unique constraint prevents duplicates. Cross-platform events (same concert on Ticketmaster AND DICE) are stored as separate rows. This plan activates the full deduplication pipeline by replacing 4 import statements and 4 call sites. It also ensures the `review_queue` table is migrated before the pipeline runs.

Output: 4 modified crawler files, `review_queue` table present in DB, full 3-stage deduplication active for all stored events.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-wire-scheduling-deduplication-pipeline/05-RESEARCH.md
@.planning/phases/05-wire-scheduling-deduplication-pipeline/05-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Migrate review_queue table to database</name>
  <files>src/db/migrations/ (new migration file generated by drizzle-kit)</files>
  <action>
The `review_queue` table is defined in `src/db/schema.ts` (lines 85-116) but has never been migrated. The existing migration files (`0000_dashing_madame_hydra.sql`, `0001_ticket_sources_migration.sql`, `0001_add_trigram_indexes.sql`) do NOT contain any `review_queue` DDL. If `deduplicateAndSave()` is called and a "maybe" match is found (similarity 70-90%), `addToReviewQueue()` in `manual-review-queue.ts` will call `db.insert(reviewQueue)` which will throw a database error because the table does not exist.

Fix: Push the schema to the database to create the `review_queue` table.

Run: `npm run db:push`

This uses `drizzle-kit push` which compares the Drizzle schema to the live database and applies any missing DDL (creating the `review_queue` table). The `--accept-data-loss` flag is NOT needed — this is only adding a new table, not modifying existing ones.

If `db:push` fails (e.g., database not running in this environment), run `npm run db:generate` instead to generate the migration SQL file and record the migration — the table will be created when the app next runs against a live DB.

Do NOT modify `src/db/schema.ts`. Do NOT modify `src/scheduling/cleanup.ts` (its comment about the review_queue is now outdated but updating it is out of scope).
  </action>
  <verify>
If `db:push` succeeded: `npm run db:push` exits 0 and reports the `review_queue` table was created.

If database is not available in this environment: `npm run db:generate` exits 0 and a new migration file exists in `src/db/migrations/` containing `CREATE TABLE review_queue` (or equivalent).

TypeScript check: `npx tsc --noEmit` still passes.
  </verify>
  <done>
Either: the `review_queue` table exists in the live database (confirmed by `db:push` output), OR a migration file exists in `src/db/migrations/` containing the `review_queue` CREATE TABLE statement so the table will be created on next deploy.
  </done>
</task>

<task type="auto">
  <name>Task 2: Replace upsertEvent with deduplicateAndSave in all four crawlers</name>
  <files>
    src/crawlers/ticketmaster.ts
    src/crawlers/axs.ts
    src/crawlers/dice.ts
    src/crawlers/venues/base-venue-crawler.ts
  </files>
  <action>
Make the following surgical import swap and call site replacement in each file. These are minimal changes — do NOT modify any surrounding logic.

**src/crawlers/ticketmaster.ts:**
- Line 17: Replace `import { upsertEvent } from '../repositories/event-repository.js';`
  with: `import { deduplicateAndSave } from '../deduplication/deduplicator.js';`
- Line 110: Replace `await upsertEvent(normalized.data);`
  with: `await deduplicateAndSave(normalized.data);`

**src/crawlers/axs.ts:**
- Line 23: Replace `import { upsertEvent } from '../repositories/event-repository.js';`
  with: `import { deduplicateAndSave } from '../deduplication/deduplicator.js';`
- Line 334: Replace `await upsertEvent(normalized.data);`
  with: `await deduplicateAndSave(normalized.data);`

**src/crawlers/dice.ts:**
- Line 3: Replace `import { upsertEvent } from '../repositories/event-repository.js';`
  with: `import { deduplicateAndSave } from '../deduplication/deduplicator.js';`
- Line 202: Replace `await upsertEvent(normalized.data);`
  with: `await deduplicateAndSave(normalized.data);`

**src/crawlers/venues/base-venue-crawler.ts:**
- Line 29: Replace `import { upsertEvent } from '../../repositories/event-repository.js';`
  with: `import { deduplicateAndSave } from '../../deduplication/deduplicator.js';`
- Line 186: Replace `await upsertEvent(normalized.data as any);`
  with: `await deduplicateAndSave(normalized.data as any);`
  (Keep the `as any` cast — it was already present and handles the transformer type mismatch)

CRITICAL: Do NOT modify `src/repositories/event-repository.ts`. The `upsertEvent()` function must remain there because `src/deduplication/deduplicator.ts` (line 41) imports and calls it internally as the final DB write step.

CRITICAL: Do NOT remove the `upsertEvent` import if the same file also uses it elsewhere — verify with grep before removing. In all four files listed above, `upsertEvent` is only used at the single call site being replaced.

If TypeScript reports a type error after the swap, use `as any` on the `deduplicateAndSave()` call argument (same pattern already used in base-venue-crawler.ts).
  </action>
  <verify>
1. Confirm no remaining `upsertEvent` imports in the four modified files:
   `grep -n "upsertEvent" src/crawlers/ticketmaster.ts src/crawlers/axs.ts src/crawlers/dice.ts src/crawlers/venues/base-venue-crawler.ts`
   Expected: zero results (the four import+call lines are gone).

2. Confirm `deduplicateAndSave` present in all four files:
   `grep -n "deduplicateAndSave" src/crawlers/ticketmaster.ts src/crawlers/axs.ts src/crawlers/dice.ts src/crawlers/venues/base-venue-crawler.ts`
   Expected: 8 lines (2 per file — import + call site).

3. Confirm `upsertEvent` still exists in the repository (must NOT be removed):
   `grep -n "upsertEvent" src/repositories/event-repository.ts`
   Expected: lines present (export function upsertEvent).

4. TypeScript compilation: `npx tsc --noEmit` — must exit 0 with no errors.
  </verify>
  <done>
All four crawlers import and call `deduplicateAndSave()` instead of `upsertEvent()`. TypeScript compiles clean. `upsertEvent` export still exists in `src/repositories/event-repository.ts`. The 3-stage deduplication pipeline is now active for every event saved by the TypeScript crawlers.
  </done>
</task>

</tasks>

<verification>
1. No `upsertEvent` imports in the four crawler files: `grep "upsertEvent" src/crawlers/ticketmaster.ts src/crawlers/axs.ts src/crawlers/dice.ts src/crawlers/venues/base-venue-crawler.ts` — must return zero lines
2. `deduplicateAndSave` present in all four files: 8 lines from grep (2 per file)
3. `upsertEvent` still exported from `src/repositories/event-repository.ts` (not removed)
4. `review_queue` table either migrated or migration file generated
5. `npx tsc --noEmit` exits 0
</verification>

<success_criteria>
- All four TypeScript crawlers call `deduplicateAndSave()` from `src/deduplication/deduplicator.ts`
- No direct `upsertEvent()` calls remain in any of the four crawler files
- `upsertEvent` still exported from `event-repository.ts` for internal use by deduplicator
- `review_queue` DB table exists (or migration file generated) so "maybe" matches don't crash the pipeline
- `npx tsc --noEmit` exits clean
- DATA-05 satisfied: deduplication pipeline active across all sources
- QUAL-01 satisfied: 3-stage fuzzy deduplication (exact match + token_set_ratio + manual review) active with pre-tuned thresholds (>90/85 = duplicate, >75/70 = manual review)
</success_criteria>

<output>
After completion, create `.planning/phases/05-wire-scheduling-deduplication-pipeline/05-02-SUMMARY.md`
</output>
