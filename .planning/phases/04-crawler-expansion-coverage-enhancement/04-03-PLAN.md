---
phase: 04-crawler-expansion-coverage-enhancement
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - crawl-gotalejon.js
  - crawl-bk.js
  - crawl-all.js
  - client/src/components/FilterBar.tsx
autonomous: true
requirements: []

must_haves:
  truths:
    - "Göta Lejon crawler fetches events from gotalejon.se JSON API and saves to database"
    - "B-K crawler extracts events from b-k.se/whats-on using Cheerio and saves to database"
    - "Both venues appear in FilterBar dropdown and crawl-all.js"
  artifacts:
    - path: "crawl-gotalejon.js"
      provides: "Göta Lejon crawler using Live Nation JSON API (venueId=77341, community=95)"
    - path: "crawl-bk.js"
      provides: "B-K venue crawler using Cheerio static HTML parsing of /whats-on"
  key_links:
    - from: "crawl-gotalejon.js"
      to: "https://www.gotalejon.se/api/search/events"
      via: "fetch with query params community=95, filter by venue.name contains Götalejon/Göta Lejon"
    - from: "crawl-bk.js"
      to: "https://www.b-k.se/whats-on"
      via: "fetch + cheerio, a[href^='/whats-on/'] containing h3/h4"
---

<objective>
Add two Stockholm venue crawlers: Göta Lejon (major rock/pop/jazz venue, uses Live Nation JSON API)
and B-K (Webflow site with static event listing). Both follow the plain Node.js ESM crawl-*.js pattern.

Purpose: Göta Lejon is one of Stockholm's premier mid-size concert venues. B-K is a newer industrial-style
venue in Frihamnen hosting major international acts. Both add meaningful coverage.

Output: crawl-gotalejon.js, crawl-bk.js, wired into crawl-all.js and FilterBar.tsx
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@crawl-all.js
@crawl-gronalund.js
@crawl-slakthusetclub.js
@client/src/components/FilterBar.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Göta Lejon crawler using Live Nation JSON API</name>
  <files>crawl-gotalejon.js</files>
  <action>
    Create crawl-gotalejon.js using the Live Nation JSON API embedded in the gotalejon.se website.

    API endpoint: GET https://www.gotalejon.se/api/search/events
    Query params to use:
    - community=95  (Göta Lejon's community ID from page __NEXT_DATA__)
    - size=100
    - page=0

    The API returns a JSON object with a "documents" array. Each document has:
    - name: event title (string)
    - eventDate: ISO date string e.g. "2026-04-15T19:00:00"
    - venue: { name: string, city: string, country: string }
    - lineup: [{ name: string, type: string, isPrimary: boolean }]
    - tickets: [{ ticketUrl: string }]
    - localizations: [{ url: string }] (Swedish URL for event page)

    Filter strategy: The API returns ~8838 global events. Filter documents where
    venue.name includes "Göta" OR venue.name includes "Lejon" OR venue.city === "Stockholm"
    AND (venue.name includes "Göta" || community filter applies).
    Since community=95 is gotalejon.se's own community, also try filtering by checking if
    localizations[].url contains "gotalejon.se". If the community filter alone doesn't
    limit to Göta Lejon events, filter by venue.name.toLowerCase().includes('göta') ||
    venue.name.toLowerCase().includes('lejon').

    Handle pagination: if total > size, fetch additional pages until all events collected.
    Limit to first 3 pages (300 events max) to avoid excessive API calls.

    For each matching event:
    - name: document.name
    - artist: primary lineup member name (lineup.find(l => l.isPrimary)?.name || document.name)
    - venue: 'Göta Lejon'
    - date: new Date(document.eventDate)
    - time: extracted from eventDate (HH:MM)
    - genre: 'other'
    - ticketSources: [{ platform: 'venue-direct', url: tickets[0]?.ticketUrl || 'https://www.gotalejon.se/kalendarium', addedAt: new Date().toISOString() }]
    - sourceId: `gotalejon-${name.toLowerCase().replace(/[^a-z0-9]/g, '-').substring(0, 60)}-${YYYY-MM-DD}`
    - sourcePlatform: 'venue-direct'

    Skip events where date < today. Upsert using standard pattern:
    db.insert(schema.events).values(event).onConflictDoUpdate({ target: [schema.events.venue, schema.events.date], set: event })

    Follow the exact same structure as crawl-gronalund.js (dotenv, postgres, drizzle, try/catch,
    client.end(), process.exit(0/1)).

    If the API returns 0 events matching Göta Lejon after filtering, log a warning
    "No Göta Lejon events found — API filter may need adjustment" and exit with code 0
    (not a crash — acceptable degraded state while API params are investigated).
  </action>
  <verify>node /Users/hussmikael/agents-hackathon/crawl-gotalejon.js 2>&1 | tail -5</verify>
  <done>crawl-gotalejon.js runs without crashing. Either saves >0 Göta Lejon events or logs a clear warning about 0 events found.</done>
</task>

<task type="auto">
  <name>Task 2: Create B-K venue crawler using Cheerio</name>
  <files>crawl-bk.js</files>
  <action>
    Create crawl-bk.js for the B-K venue (b-k.se) at Frihamnsgatan 14, Stockholm.

    URL: https://www.b-k.se/whats-on
    This is a Webflow site with static HTML. Events are listed as anchor tags.

    Selector strategy:
    - Find all: $('a[href^="/whats-on/"]') — these are individual event page links
    - Each link contains a heading (h3 or h4) with the artist/event name
    - Date appears as text in the link or in a sibling/child element
    - Date format observed: "Mar 5, 2026" or "March 5, 2026"

    For each event link:
    1. href: link.attr('href') → construct full URL as 'https://www.b-k.se' + href
    2. title: link.find('h3, h4').first().text().trim()
       — if empty, try link.find('[class*="heading"], [class*="title"]').first().text().trim()
    3. dateText: Extract from link's text content — look for pattern matching
       /\w+\s+\d{1,2},?\s+\d{4}/ (e.g. "Mar 5, 2026") or /\d{1,2}\s+\w+\s+\d{4}/
       Try: link.text() and extract date using regex
    4. Parse date: Use Date constructor with the extracted date string.
       Handle month abbreviations: Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    5. Skip events without a parseable date or title
    6. Skip events where date < today
    7. Default time: '19:00' (standard B-K door time)

    Deduplication: use a Set of href values to avoid processing the same event link twice
    (Webflow pages often repeat event links in different sections).

    sourceId: `bk-${title.toLowerCase().replace(/[^a-z0-9]/g, '-').substring(0, 60)}-${YYYY-MM-DD}`

    Follow exact structure as crawl-gronalund.js (dotenv, postgres, drizzle, cheerio,
    try/catch per event, final client.end(), process.exit(0/1)).

    genre: 'other'
    VENUE_NAME: 'B-K'
  </action>
  <verify>node /Users/hussmikael/agents-hackathon/crawl-bk.js 2>&1 | tail -5</verify>
  <done>crawl-bk.js runs without crashing. Returns >0 events from b-k.se/whats-on.</done>
</task>

<task type="auto">
  <name>Task 3: Wire both crawlers into crawl-all.js and FilterBar</name>
  <files>crawl-all.js, client/src/components/FilterBar.tsx</files>
  <action>
    In crawl-all.js: Add two entries to the crawlers array (after the Fredagsmangel entry):
    - { name: 'Göta Lejon', file: './crawl-gotalejon.js' }
    - { name: 'B-K', file: './crawl-bk.js' }

    In client/src/components/FilterBar.tsx: Add two option elements to the venue select
    dropdown (after the Fredagsmangel option):
    - <option value="Göta Lejon">Göta Lejon</option>
    - <option value="B-K">B-K</option>
  </action>
  <verify>grep -n "Göta Lejon\|B-K" /Users/hussmikael/agents-hackathon/crawl-all.js /Users/hussmikael/agents-hackathon/client/src/components/FilterBar.tsx</verify>
  <done>Both venues appear in crawl-all.js crawlers array and FilterBar.tsx venue dropdown.</done>
</task>

</tasks>

<verification>
1. node crawl-gotalejon.js exits with code 0 (either events saved or graceful 0-event warning)
2. node crawl-bk.js exits with code 0 and reports >0 events saved
3. Both venue names present in crawl-all.js and FilterBar.tsx
</verification>

<success_criteria>
1. crawl-gotalejon.js exists and runs without crashing
2. crawl-bk.js exists and saves >0 events from b-k.se
3. Both venues in crawl-all.js and FilterBar dropdown
4. Pattern matches other crawl-*.js scripts (dotenv, postgres, drizzle, try/catch, process.exit)
</success_criteria>

<output>
After completion, create `.planning/phases/04-crawler-expansion-coverage-enhancement/04-03-SUMMARY.md`
</output>
